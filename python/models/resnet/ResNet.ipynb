{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ===== Import necessary libraries =====\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torch.quantization\n",
    "from torch.quantization import QConfig, default_observer, default_per_channel_weight_observer\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# ===== Set up the SimpleNN model =====\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, quantTrue=False):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_weights(self, current_sparsity, target_sparsity):\n",
    "        remaining_weights = 1.0 - current_sparsity\n",
    "        pruning_ratio = 1.0 - (target_sparsity / remaining_weights)\n",
    "        if current_sparsity == 0.0:\n",
    "            pruning_ratio = target_sparsity\n",
    "        print(\"Pruning Ratio:\" + str(pruning_ratio))\n",
    "        prune.l1_unstructured(self.conv, 'weight', amount=pruning_ratio)\n",
    "\n",
    "\n",
    "    def to_sparse(self):\n",
    "        self.conv.weight = nn.Parameter(self.conv.weight.to_sparse())\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1, quantTrue=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion*out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            )\n",
    "        \n",
    "        self.quantadd = nn.quantized.FloatFunctional()\n",
    "\n",
    "        self.quantTrue = quantTrue\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.quantTrue:\n",
    "            if self.shortcut is not None:\n",
    "                identity = self.shortcut(identity)\n",
    "            out = self.quantadd.add(out, identity)\n",
    "        else:\n",
    "            if self.shortcut is not None:\n",
    "                identity = self.shortcut(identity)\n",
    "            out += identity\n",
    "\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "    def prune_weights(self, current_sparsity, target_sparsity):\n",
    "        remaining_weights = 1.0 - current_sparsity\n",
    "        pruning_ratio = 1.0 - (target_sparsity / remaining_weights)\n",
    "        if current_sparsity == 0.0:\n",
    "            pruning_ratio = target_sparsity\n",
    "        print(\"Pruning Ratio:\" + str(pruning_ratio))\n",
    "        prune.l1_unstructured(self.conv1, 'weight', amount=pruning_ratio)\n",
    "        prune.l1_unstructured(self.conv2, 'weight', amount=pruning_ratio)\n",
    "\n",
    "    def to_sparse(self):\n",
    "        self.conv1.weight = nn.Parameter(self.conv1.weight.to_sparse())\n",
    "        self.conv2.weight = nn.Parameter(self.conv2.weight.to_sparse())\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, architecture_type='cnn', quantTrue = False, conv_layer_configs=None, fc_layer_configs=None, res_block_configs=None, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Initialization code for other parts of the class remains the same\n",
    "        \n",
    "        if architecture_type == 'cnn':\n",
    "            self.myNetworkType = 'cnn'\n",
    "            self.features = self._make_cnn_layers(conv_layer_configs)\n",
    "            prev_features = conv_layer_configs[-1]['out_channels']\n",
    "        elif architecture_type == 'resnet':\n",
    "            self.myNetworkType = 'resnet'\n",
    "            self.init_conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.init_bn = nn.BatchNorm2d(16)\n",
    "            self.init_relu = nn.ReLU(inplace=True)\n",
    "            self.features, prev_features = self._make_resnet_layers(res_block_configs, quantTrue)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported architecture type: {}\".format(architecture_type))\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = self._make_fc_layers(prev_features, fc_layer_configs, num_classes)\n",
    "\n",
    "    def _make_cnn_layers(self, conv_layer_configs):\n",
    "        layers = []\n",
    "        for conv_layer in conv_layer_configs:\n",
    "            in_channels = conv_layer['in_channels']\n",
    "            out_channels = conv_layer['out_channels']\n",
    "            kernel_size = conv_layer['kernel_size']\n",
    "            stride = conv_layer['stride']\n",
    "            padding = conv_layer['padding']\n",
    "            block = CNNBlock(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            layers.append(block)\n",
    "        in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_resnet_layers(self, res_block_configs, quantTrue=False):\n",
    "        layers = []\n",
    "        for block_config in res_block_configs:\n",
    "            in_channels = block_config['in_channels']\n",
    "            out_channels = block_config['out_channels']\n",
    "            num_blocks = block_config['num_blocks']\n",
    "            stride = block_config['stride']\n",
    "            \n",
    "            layers.append(self._make_layer(ResBlock, in_channels, out_channels, num_blocks, stride, quantTrue=quantTrue))\n",
    "            \n",
    "            # Update in_channels for the next set of blocks\n",
    "            in_channels = out_channels * ResBlock.expansion\n",
    "        return nn.Sequential(*layers), in_channels\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, num_blocks, stride, quantTrue = False):\n",
    "        strides = [stride] + [1]*(num_blocks-1)  # First block might have a stride to downsample\n",
    "        blocks = []\n",
    "        for stride in strides:\n",
    "            blocks.append(block(in_channels, out_channels, stride, quantTrue=quantTrue))\n",
    "            in_channels = out_channels * block.expansion  # Update in_channels for the next block\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def _make_fc_layers(self, prev_features, fc_layer_configs, num_classes):\n",
    "        layers = nn.ModuleList()\n",
    "        if fc_layer_configs is not None:\n",
    "            for fc_layer in fc_layer_configs:\n",
    "                layers.append(nn.Linear(prev_features, fc_layer['out_features']))\n",
    "                prev_features = fc_layer['out_features']\n",
    "            layers.append(nn.Linear(prev_features, num_classes))\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = F.relu(layer(x))\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class QuantizablePrunableCNN(CNN):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(QuantizablePrunableCNN, self).__init__(*args, **kwargs)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_weights(self, current_sparsity, target_sparsity=0.5):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (CNNBlock, ResBlock)):\n",
    "                module.prune_weights(current_sparsity, target_sparsity)\n",
    "\n",
    "    def convert_to_sparse(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (CNNBlock, ResBlock)):\n",
    "                module.to_sparse()\n",
    "\n",
    "\n",
    "\n",
    "# ===== Define and set HyperParameters =====\n",
    "\n",
    "\n",
    "## DataLoader\n",
    "TRAIN_BATCH_SIZE = 64  # training batch size\n",
    "VAL_BATCH_SIZE = 50  # validation batch size\n",
    "NUM_WORKERS = 8  # number of workers for DataLoader\n",
    "\n",
    "## Model\n",
    "### CNN\n",
    "conv_layer_configs = [\n",
    "    {'in_channels': 3, 'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'in_channels': 32, 'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'in_channels': 64, 'out_channels': 128, 'kernel_size': 3, 'stride': 2, 'padding': 1}\n",
    "]\n",
    "\n",
    "fc_layer_configs = [\n",
    "    {'out_features': 256},\n",
    "    {'out_features': 128}\n",
    "]\n",
    "\n",
    "### ResNet\n",
    "res_block_configs = [\n",
    "    {'in_channels': 3, 'out_channels': 16, 'stride': 1, 'num_blocks': 3},\n",
    "    {'in_channels': 16, 'out_channels': 32, 'stride': 2, 'num_blocks': 3},\n",
    "    {'in_channels': 32, 'out_channels': 64, 'stride': 2, 'num_blocks': 3}\n",
    "]\n",
    "\n",
    "## Optimizer and scheduler\n",
    "INITIAL_LR = 0.1  # initial learning rate\n",
    "MOMENTUM = 0.9  # momentum for optimizer\n",
    "REG = 1e-4  # L2 regularization strength\n",
    "LR_PATIENCE = 5  # Patience for ReduceLROnPlateau scheduler\n",
    "LR_FACTOR = 0.25  # Factor by which the learning rate will be reduced\n",
    "\n",
    "## Training\n",
    "EPOCHS = 5  # total number of training epochs\n",
    "CHECKPOINT_FOLDER = \"./saved_models\"  # folder where models are saved\n",
    "\n",
    "## Pruning and Quantization\n",
    "ENABLE_QUANTIZATION = False\n",
    "ENABLE_PRUNING = True\n",
    "pruning_epochs = 3\n",
    "starting_sparsity = 0.1\n",
    "target_sparsity = 0.5\n",
    "\n",
    "# ===== Set up preprocessing functions =====\n",
    "\n",
    "\n",
    "## specify preprocessing function\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\n",
    "# ===== Set up dataset and dataloader =====\n",
    "\n",
    "\n",
    "DATA_ROOT = \"./data\"\n",
    "\n",
    "## construct dataset\n",
    "train_set = CIFAR10(\n",
    "    root = DATA_ROOT, \n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform_train\n",
    ")\n",
    "val_set = CIFAR10(\n",
    "    root = DATA_ROOT, \n",
    "    train = False, \n",
    "    download = True,\n",
    "    transform = transform_val\n",
    ")\n",
    "\n",
    "## construct dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size= TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "# ===== Instantiate your SimpleNN model and deploy it to device =====\n",
    "\n",
    "\n",
    "## specify the device for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = QuantizablePrunableCNN(architecture_type='resnet', quantTrue=ENABLE_QUANTIZATION, res_block_configs=res_block_configs, num_classes=10) \n",
    "# net = QuantizableCNN(architecture_type='cnn', quantTrue=ENABLE_QUANTIZATION, conv_layer_configs=conv_layer_configs, fc_layer_configs=fc_layer_configs, num_classes=10)\n",
    "\n",
    "\n",
    "if ENABLE_QUANTIZATION:\n",
    "    my_qconfig = QConfig(\n",
    "    activation=torch.quantization.default_observer.with_args(dtype=torch.quint8),\n",
    "    weight=torch.quantization.default_weight_observer.with_args(dtype=torch.qint8)\n",
    "    )\n",
    "    net.qconfig = my_qconfig\n",
    "    torch.quantization.prepare_qat(net, inplace=True)\n",
    "\n",
    "# deploy the network to device\n",
    "net.to(device)\n",
    "\n",
    "print(next(net.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.3 0.5 0.5 0.5]\n",
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0: with learning rate 0.1\n",
      "Training loss: 111.9887, Training accuracy: 0.3638\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning Ratio:0.9\n",
      "Pruning to 10.00% sparsity level\n",
      "Validation loss: 150.9558, Validation accuracy: 0.1055\n",
      "Saving ...\n",
      "\n",
      "Epoch 1: with learning rate 0.1\n",
      "Training loss: 84.8208, Training accuracy: 0.5188\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning Ratio:0.6666666666666666\n",
      "Pruning to 30.00% sparsity level\n",
      "Validation loss: 229.4842, Validation accuracy: 0.1198\n",
      "Saving ...\n",
      "\n",
      "Epoch 2: with learning rate 0.1\n",
      "Training loss: 77.0758, Training accuracy: 0.5676\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning Ratio:0.2857142857142857\n",
      "Pruning to 50.00% sparsity level\n",
      "Validation loss: 104.5117, Validation accuracy: 0.3462\n",
      "Saving ...\n",
      "\n",
      "Epoch 3: with learning rate 0.1\n",
      "Training loss: 72.9350, Training accuracy: 0.5950\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning to 50.00% sparsity level\n",
      "Validation loss: 51.0761, Validation accuracy: 0.6395\n",
      "Saving ...\n",
      "\n",
      "Epoch 4: with learning rate 0.1\n",
      "Training loss: 70.7996, Training accuracy: 0.6068\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning Ratio:0.0\n",
      "Pruning to 50.00% sparsity level\n",
      "Validation loss: 52.9729, Validation accuracy: 0.6325\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.6395\n"
     ]
    }
   ],
   "source": [
    "def make_pruning_schedule(pruning_epochs, total_epochs, start_sparsity, final_sparsity):\n",
    "    sparsity_levels = np.linspace(start_sparsity, final_sparsity, num=pruning_epochs)\n",
    "    for i in range(total_epochs - pruning_epochs):\n",
    "        sparsity_levels = np.append(sparsity_levels, final_sparsity)\n",
    "    return sparsity_levels\n",
    "\n",
    "# ===== Set up the loss function and optimizer =====\n",
    "\n",
    "\n",
    "## loss function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "## Add optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=LR_PATIENCE, factor=LR_FACTOR)\n",
    "\n",
    "pruning_schedule = make_pruning_schedule(pruning_epochs, EPOCHS, starting_sparsity, target_sparsity)\n",
    "print(pruning_schedule)\n",
    "\n",
    "# ===== Start the training process =====\n",
    "\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "print(\"==> Training starts!\")\n",
    "print(\"=\"*50)\n",
    "for i in range(0, EPOCHS):    \n",
    "    ## switch to train mode\n",
    "    net.train()\n",
    "\n",
    "    ## print the Epoch and learning rate\n",
    "    current_learning_rate = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {i}: with learning rate {current_learning_rate}\")\n",
    "    \n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    ## Train the model\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        ### copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        ### compute the output and loss\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets.long())\n",
    "        \n",
    "        ### zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ### apply gradient and update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### count the number of correctly predicted samples in the current batch\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_examples += targets.size(0)\n",
    "        correct_examples += (predicted == targets).sum().item()\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "                \n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "\n",
    "    if ENABLE_PRUNING:\n",
    "        current_sparsity = pruning_schedule[i-1] if i > 0 else 0\n",
    "        target_sparsity = pruning_schedule[i]\n",
    "        net.prune_weights(current_sparsity, target_sparsity)\n",
    "        print(f\"Pruning to {target_sparsity:.2%} sparsity level\")\n",
    "\n",
    "    ## Validate on the validation dataset\n",
    "    ## switch to eval mode\n",
    "    net.eval()\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    ## disable gradient during validation, which can save GPU memory\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            ### copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            ### compute the output and loss\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets.long())\n",
    "            \n",
    "            ### count the number of correctly predicted samples in the current batch\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_examples += targets.size(0)\n",
    "            correct_examples += (predicted == targets).sum().item()\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "\n",
    "    ## decay learning rate\n",
    "    previous_learning_rate = current_learning_rate\n",
    "    scheduler.step(val_loss)\n",
    "    current_learning_rate = optimizer.param_groups[0]['lr']\n",
    "    if previous_learning_rate != current_learning_rate:\n",
    "        print(f\"Learning rate decayed to {current_learning_rate}\")\n",
    "    \n",
    "    ## save the model checkpoint\n",
    "    if avg_acc > best_val_acc:\n",
    "        best_val_acc = avg_acc\n",
    "        if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "           os.makedirs(CHECKPOINT_FOLDER)\n",
    "        print(\"Saving ...\")\n",
    "        state = {'state_dict': net.state_dict(),\n",
    "                'epoch': i,\n",
    "                'lr': current_learning_rate}\n",
    "        saveName = 'CNN_quantizeTrained' if ENABLE_QUANTIZATION else 'CNN'\n",
    "        torch.save(state, os.path.join(CHECKPOINT_FOLDER, saveName + '.pth'))\n",
    "    print('')\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in init_conv: 0.00%\n",
      "Sparsity in features.0.0.conv1: 97.69%\n",
      "Sparsity in features.0.0.conv2: 97.61%\n",
      "Sparsity in features.0.0.shortcut.0: 0.00%\n",
      "Sparsity in features.0.1.conv1: 97.61%\n",
      "Sparsity in features.0.1.conv2: 97.61%\n",
      "Sparsity in features.0.2.conv1: 97.61%\n",
      "Sparsity in features.0.2.conv2: 97.61%\n",
      "Sparsity in features.1.0.conv1: 97.61%\n",
      "Sparsity in features.1.0.conv2: 97.62%\n",
      "Sparsity in features.1.0.shortcut.0: 0.00%\n",
      "Sparsity in features.1.1.conv1: 97.62%\n",
      "Sparsity in features.1.1.conv2: 97.62%\n",
      "Sparsity in features.1.2.conv1: 97.62%\n",
      "Sparsity in features.1.2.conv2: 97.62%\n",
      "Sparsity in features.2.0.conv1: 97.62%\n",
      "Sparsity in features.2.0.conv2: 97.62%\n",
      "Sparsity in features.2.0.shortcut.0: 0.00%\n",
      "Sparsity in features.2.1.conv1: 97.62%\n",
      "Sparsity in features.2.1.conv2: 97.62%\n",
      "Sparsity in features.2.2.conv1: 97.62%\n",
      "Sparsity in features.2.2.conv2: 97.62%\n",
      "Converting to sparse model\n"
     ]
    }
   ],
   "source": [
    "def check_sparsity(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            weight = module.weight.data\n",
    "            if weight.is_sparse:\n",
    "                weight = weight.to_dense()\n",
    "            weight = weight.cpu()\n",
    "            sparsity = float(torch.sum(weight == 0)) / float(weight.nelement())\n",
    "            print(f\"Sparsity in {name}: {sparsity * 100:.2f}%\")\n",
    "\n",
    "check_sparsity(net)\n",
    "\n",
    "if ENABLE_PRUNING:\n",
    "    net.convert_to_sparse()\n",
    "    print(\"Converting to sparse model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Size: 2.32 MB\n"
     ]
    }
   ],
   "source": [
    "quantizedModel = True\n",
    "net.to('cpu')\n",
    "device = 'cpu'\n",
    "torch.quantization.convert(net.eval(), inplace=True)\n",
    "\n",
    "saveName = 'CNN' + '_quantized' if quantizedModel else 'CNN'\n",
    "torch.save(net.state_dict(), os.path.join(CHECKPOINT_FOLDER, saveName + '.pth'))\n",
    "\n",
    "# Check the size of the quantized model\n",
    "model_size_bytes = os.path.getsize(CHECKPOINT_FOLDER + '/' + saveName + '.pth')\n",
    "model_size_mb = model_size_bytes / (1024 * 1024)  # Convert bytes to megabytes\n",
    "print(f\"Quantized Model Size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.FloatTensor' as parameter 'weight' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m---> 21\u001b[0m evaluate_model(net, val_loader)\n",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, data_loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      9\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     11\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 186\u001b[0m, in \u001b[0;36mQuantizablePrunableCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    185\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant(x)\n\u001b[1;32m--> 186\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m    187\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdequant(x)\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[1;32mIn[1], line 167\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 167\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[0;32m    168\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madaptive_pool(x)\n\u001b[0;32m    169\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     70\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 71\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m     72\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     73\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1550\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1545\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1546\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward pre-hook must return None or a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1547\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs_kwargs_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1548\u001b[0m             )\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     args_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args)\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1552\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\prune.py:30\u001b[0m, in \u001b[0;36mBasePruningMethod.__call__\u001b[1;34m(self, module, inputs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, module, inputs):\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Multiply the mask into original tensor and store the result.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    Multiplies the mask (stored in ``module[name + '_mask']``)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m        inputs: not used.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_mask(module))\n",
      "File \u001b[1;32mc:\\Users\\barto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1708\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   1706\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1708\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mtypename(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1709\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(torch.nn.Parameter or None expected)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1710\u001b[0m                         )\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(name, value)\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot assign 'torch.FloatTensor' as parameter 'weight' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss += criterion(outputs, labels).item() * images.size(0)\n",
    "    \n",
    "    avg_loss = loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "evaluate_model(net, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
