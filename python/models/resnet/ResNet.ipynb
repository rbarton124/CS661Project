{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ===== Import necessary libraries =====\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torch.quantization\n",
    "from torch.quantization import QConfig, default_observer, default_per_channel_weight_observer\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# ===== Set up the SimpleNN model =====\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, quantTrue=False):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_weights(self, amount):\n",
    "        prune.l1_unstructured(self.conv, 'weight', amount=amount)\n",
    "\n",
    "    def to_sparse(self):\n",
    "        self.conv.weight = nn.Parameter(self.conv.weight.to_sparse())\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1, quantTrue=False):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion*out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            )\n",
    "        \n",
    "        self.quantadd = nn.quantized.FloatFunctional()\n",
    "\n",
    "        self.quantTrue = quantTrue\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.quantTrue:\n",
    "            if self.shortcut is not None:\n",
    "                identity = self.shortcut(identity)\n",
    "            out = self.quantadd.add(out, identity)\n",
    "        else:\n",
    "            if self.shortcut is not None:\n",
    "                identity = self.shortcut(identity)\n",
    "            out += identity\n",
    "\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "    def prune_weights(self, amount):\n",
    "        prune.l1_unstructured(self.conv1, 'weight', amount=amount)\n",
    "        prune.l1_unstructured(self.conv2, 'weight', amount=amount)\n",
    "\n",
    "    def to_sparse(self):\n",
    "        self.conv1.weight = nn.Parameter(self.conv1.weight.to_sparse())\n",
    "        self.conv2.weight = nn.Parameter(self.conv2.weight.to_sparse())\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, architecture_type='cnn', quantTrue = False, conv_layer_configs=None, fc_layer_configs=None, res_block_configs=None, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Initialization code for other parts of the class remains the same\n",
    "        \n",
    "        if architecture_type == 'cnn':\n",
    "            self.myNetworkType = 'cnn'\n",
    "            self.features = self._make_cnn_layers(conv_layer_configs)\n",
    "            prev_features = conv_layer_configs[-1]['out_channels']\n",
    "        elif architecture_type == 'resnet':\n",
    "            self.myNetworkType = 'resnet'\n",
    "            self.init_conv = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.init_bn = nn.BatchNorm2d(16)\n",
    "            self.init_relu = nn.ReLU(inplace=True)\n",
    "            self.features, prev_features = self._make_resnet_layers(res_block_configs, quantTrue)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported architecture type: {}\".format(architecture_type))\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = self._make_fc_layers(prev_features, fc_layer_configs, num_classes)\n",
    "\n",
    "    def _make_cnn_layers(self, conv_layer_configs):\n",
    "        layers = []\n",
    "        for conv_layer in conv_layer_configs:\n",
    "            in_channels = conv_layer['in_channels']\n",
    "            out_channels = conv_layer['out_channels']\n",
    "            kernel_size = conv_layer['kernel_size']\n",
    "            stride = conv_layer['stride']\n",
    "            padding = conv_layer['padding']\n",
    "            block = CNNBlock(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            layers.append(block)\n",
    "        in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_resnet_layers(self, res_block_configs, quantTrue=False):\n",
    "        layers = []\n",
    "        for block_config in res_block_configs:\n",
    "            in_channels = block_config['in_channels']\n",
    "            out_channels = block_config['out_channels']\n",
    "            num_blocks = block_config['num_blocks']\n",
    "            stride = block_config['stride']\n",
    "            \n",
    "            layers.append(self._make_layer(ResBlock, in_channels, out_channels, num_blocks, stride, quantTrue=quantTrue))\n",
    "            \n",
    "            # Update in_channels for the next set of blocks\n",
    "            in_channels = out_channels * ResBlock.expansion\n",
    "        return nn.Sequential(*layers), in_channels\n",
    "\n",
    "    def _make_layer(self, block, in_channels, out_channels, num_blocks, stride, quantTrue = False):\n",
    "        strides = [stride] + [1]*(num_blocks-1)  # First block might have a stride to downsample\n",
    "        blocks = []\n",
    "        for stride in strides:\n",
    "            blocks.append(block(in_channels, out_channels, stride, quantTrue=quantTrue))\n",
    "            in_channels = out_channels * block.expansion  # Update in_channels for the next block\n",
    "        return nn.Sequential(*blocks)\n",
    "\n",
    "    def _make_fc_layers(self, prev_features, fc_layer_configs, num_classes):\n",
    "        layers = nn.ModuleList()\n",
    "        if fc_layer_configs is not None:\n",
    "            for fc_layer in fc_layer_configs:\n",
    "                layers.append(nn.Linear(prev_features, fc_layer['out_features']))\n",
    "                prev_features = fc_layer['out_features']\n",
    "            layers.append(nn.Linear(prev_features, num_classes))\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = F.relu(layer(x))\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class QuantizablePrunableCNN(CNN):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(QuantizablePrunableCNN, self).__init__(*args, **kwargs)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "    \n",
    "    def prune_weights(self, amount=0.15):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (CNNBlock, ResBlock)):\n",
    "                module.prune_weights(amount)\n",
    "\n",
    "    def convert_to_sparse(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (CNNBlock, ResBlock)):\n",
    "                module.to_sparse()\n",
    "\n",
    "\n",
    "\n",
    "# ===== Define and set HyperParameters =====\n",
    "\n",
    "\n",
    "## DataLoader\n",
    "TRAIN_BATCH_SIZE = 64  # training batch size\n",
    "VAL_BATCH_SIZE = 50  # validation batch size\n",
    "NUM_WORKERS = 8  # number of workers for DataLoader\n",
    "\n",
    "## Model\n",
    "### CNN\n",
    "conv_layer_configs = [\n",
    "    {'in_channels': 3, 'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'in_channels': 32, 'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'in_channels': 64, 'out_channels': 128, 'kernel_size': 3, 'stride': 2, 'padding': 1}\n",
    "]\n",
    "\n",
    "fc_layer_configs = [\n",
    "    {'out_features': 256},\n",
    "    {'out_features': 128}\n",
    "]\n",
    "\n",
    "### ResNet\n",
    "res_block_configs = [\n",
    "    {'in_channels': 3, 'out_channels': 16, 'stride': 1, 'num_blocks': 3},\n",
    "    {'in_channels': 16, 'out_channels': 32, 'stride': 2, 'num_blocks': 3},\n",
    "    {'in_channels': 32, 'out_channels': 64, 'stride': 2, 'num_blocks': 3}\n",
    "]\n",
    "\n",
    "## Optimizer and scheduler\n",
    "INITIAL_LR = 0.1  # initial learning rate\n",
    "MOMENTUM = 0.9  # momentum for optimizer\n",
    "REG = 1e-4  # L2 regularization strength\n",
    "LR_PATIENCE = 5  # Patience for ReduceLROnPlateau scheduler\n",
    "LR_FACTOR = 0.25  # Factor by which the learning rate will be reduced\n",
    "\n",
    "## Training\n",
    "EPOCHS = 20  # total number of training epochs\n",
    "CHECKPOINT_FOLDER = \"./saved_models\"  # folder where models are saved\n",
    "\n",
    "## Pruning and Quantization\n",
    "ENABLE_QUANTIZATION = False\n",
    "ENABLE_PRUNING = True\n",
    "\n",
    "# ===== Set up preprocessing functions =====\n",
    "\n",
    "\n",
    "## specify preprocessing function\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\n",
    "# ===== Set up dataset and dataloader =====\n",
    "\n",
    "\n",
    "DATA_ROOT = \"./data\"\n",
    "\n",
    "## construct dataset\n",
    "train_set = CIFAR10(\n",
    "    root = DATA_ROOT, \n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform_train\n",
    ")\n",
    "val_set = CIFAR10(\n",
    "    root = DATA_ROOT, \n",
    "    train = False, \n",
    "    download = True,\n",
    "    transform = transform_val\n",
    ")\n",
    "\n",
    "## construct dataloader\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    batch_size= TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, \n",
    "    batch_size=VAL_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "# ===== Instantiate your SimpleNN model and deploy it to device =====\n",
    "\n",
    "\n",
    "## specify the device for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = QuantizablePrunableCNN(architecture_type='resnet', quantTrue=ENABLE_QUANTIZATION, res_block_configs=res_block_configs, num_classes=10) \n",
    "# net = QuantizableCNN(architecture_type='cnn', quantTrue=ENABLE_QUANTIZATION, conv_layer_configs=conv_layer_configs, fc_layer_configs=fc_layer_configs, num_classes=10)\n",
    "\n",
    "\n",
    "if ENABLE_QUANTIZATION:\n",
    "    my_qconfig = QConfig(\n",
    "    activation=torch.quantization.default_observer.with_args(dtype=torch.quint8),\n",
    "    weight=torch.quantization.default_weight_observer.with_args(dtype=torch.qint8)\n",
    "    )\n",
    "    net.qconfig = my_qconfig\n",
    "    torch.quantization.prepare_qat(net, inplace=True)\n",
    "\n",
    "# deploy the network to device\n",
    "net.to(device)\n",
    "\n",
    "print(next(net.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training starts!\n",
      "==================================================\n",
      "Epoch 0: with learning rate 0.1\n",
      "Training loss: 107.4068, Training accuracy: 0.3966\n",
      "Applying pruning...\n",
      "Validation loss: 77.7536, Validation accuracy: 0.4654\n",
      "Saving ...\n",
      "\n",
      "Epoch 1: with learning rate 0.1\n",
      "Training loss: 76.4311, Training accuracy: 0.5714\n",
      "Applying pruning...\n",
      "Validation loss: 158.4893, Validation accuracy: 0.2813\n",
      "\n",
      "Epoch 2: with learning rate 0.1\n",
      "Training loss: 66.3811, Training accuracy: 0.6280\n",
      "Applying pruning...\n",
      "Validation loss: 182.2176, Validation accuracy: 0.1832\n",
      "\n",
      "Epoch 3: with learning rate 0.1\n",
      "Training loss: 61.5980, Training accuracy: 0.6586\n",
      "Applying pruning...\n",
      "Validation loss: 240.5983, Validation accuracy: 0.1675\n",
      "\n",
      "Epoch 4: with learning rate 0.1\n",
      "Training loss: 61.0512, Training accuracy: 0.6639\n",
      "Applying pruning...\n",
      "Validation loss: 252.7767, Validation accuracy: 0.1136\n",
      "\n",
      "Epoch 5: with learning rate 0.1\n",
      "Training loss: 63.7932, Training accuracy: 0.6467\n",
      "Applying pruning...\n",
      "Validation loss: 142.1216, Validation accuracy: 0.1930\n",
      "\n",
      "Epoch 6: with learning rate 0.1\n",
      "Training loss: 68.2787, Training accuracy: 0.6238\n",
      "Applying pruning...\n",
      "Validation loss: 1206.9914, Validation accuracy: 0.0000\n",
      "Learning rate decayed to 0.025\n",
      "\n",
      "Epoch 7: with learning rate 0.025\n",
      "Training loss: 77.9513, Training accuracy: 0.5667\n",
      "Applying pruning...\n",
      "Validation loss: 415.7070, Validation accuracy: 0.1147\n",
      "\n",
      "Epoch 8: with learning rate 0.025\n",
      "Training loss: 96.4888, Training accuracy: 0.4539\n",
      "Applying pruning...\n",
      "Validation loss: 3174.4947, Validation accuracy: 0.1000\n",
      "\n",
      "Epoch 9: with learning rate 0.025\n",
      "Training loss: 98.0072, Training accuracy: 0.4420\n",
      "Applying pruning...\n",
      "Validation loss: 177.5618, Validation accuracy: 0.1243\n",
      "\n",
      "Epoch 10: with learning rate 0.025\n",
      "Training loss: 108.9122, Training accuracy: 0.3850\n",
      "Applying pruning...\n",
      "Validation loss: 289.1977, Validation accuracy: 0.1343\n",
      "\n",
      "Epoch 11: with learning rate 0.025\n",
      "Training loss: 118.2133, Training accuracy: 0.3231\n",
      "Applying pruning...\n",
      "Validation loss: 159.2794, Validation accuracy: 0.1806\n",
      "\n",
      "Epoch 12: with learning rate 0.025\n",
      "Training loss: 123.1622, Training accuracy: 0.2901\n",
      "Applying pruning...\n",
      "Validation loss: 2958.9555, Validation accuracy: 0.1000\n",
      "Learning rate decayed to 0.00625\n",
      "\n",
      "Epoch 13: with learning rate 0.00625\n",
      "Training loss: 122.1977, Training accuracy: 0.2990\n",
      "Applying pruning...\n",
      "Validation loss: 156.1072, Validation accuracy: 0.2528\n",
      "\n",
      "Epoch 14: with learning rate 0.00625\n",
      "Training loss: 123.0948, Training accuracy: 0.2939\n",
      "Applying pruning...\n",
      "Validation loss: 311.4273, Validation accuracy: 0.1000\n",
      "\n",
      "Epoch 15: with learning rate 0.00625\n",
      "Training loss: 123.5911, Training accuracy: 0.2883\n",
      "Applying pruning...\n",
      "Validation loss: 94.8494, Validation accuracy: 0.3142\n",
      "\n",
      "Epoch 16: with learning rate 0.00625\n",
      "Training loss: 122.8194, Training accuracy: 0.2974\n",
      "Applying pruning...\n",
      "Validation loss: 94.2000, Validation accuracy: 0.3192\n",
      "\n",
      "Epoch 17: with learning rate 0.00625\n",
      "Training loss: 122.4463, Training accuracy: 0.2964\n",
      "Applying pruning...\n",
      "Validation loss: 94.0098, Validation accuracy: 0.3217\n",
      "\n",
      "Epoch 18: with learning rate 0.00625\n",
      "Training loss: 122.3770, Training accuracy: 0.2992\n",
      "Applying pruning...\n",
      "Validation loss: 93.3199, Validation accuracy: 0.3268\n",
      "Learning rate decayed to 0.0015625\n",
      "\n",
      "Epoch 19: with learning rate 0.0015625\n",
      "Training loss: 121.8441, Training accuracy: 0.3023\n",
      "Applying pruning...\n",
      "Validation loss: 92.7436, Validation accuracy: 0.3335\n",
      "\n",
      "==================================================\n",
      "==> Optimization finished! Best validation accuracy: 0.4654\n"
     ]
    }
   ],
   "source": [
    "# ===== Set up the loss function and optimizer =====\n",
    "\n",
    "\n",
    "## loss function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "## Add optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=LR_PATIENCE, factor=LR_FACTOR)\n",
    "\n",
    "## Pruning Array\n",
    "PruningArray = np.linspace(0.0, 0.5, EPOCHS)\n",
    "\n",
    "\n",
    "# ===== Start the training process =====\n",
    "\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "print(\"==> Training starts!\")\n",
    "print(\"=\"*50)\n",
    "for i in range(0, EPOCHS):    \n",
    "    ## switch to train mode\n",
    "    net.train()\n",
    "\n",
    "    ## print the Epoch and learning rate\n",
    "    current_learning_rate = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {i}: with learning rate {current_learning_rate}\")\n",
    "    \n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    ## Train the model\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        ### copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        ### compute the output and loss\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets.long())\n",
    "        \n",
    "        ### zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ### apply gradient and update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### count the number of correctly predicted samples in the current batch\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_examples += targets.size(0)\n",
    "        correct_examples += (predicted == targets).sum().item()\n",
    "        train_loss += loss.item()*inputs.size(0)\n",
    "                \n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "\n",
    "    if ENABLE_PRUNING:\n",
    "        net.prune_weights(PruningArray[i])\n",
    "        print(\"Applying pruning: \" + f\"{PruningArray[i]:.2%}\" )\n",
    "\n",
    "    ## Validate on the validation dataset\n",
    "    ## switch to eval mode\n",
    "    net.eval()\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    ## disable gradient during validation, which can save GPU memory\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            ### copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            ### compute the output and loss\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets.long())\n",
    "            \n",
    "            ### count the number of correctly predicted samples in the current batch\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_examples += targets.size(0)\n",
    "            correct_examples += (predicted == targets).sum().item()\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "\n",
    "    ## decay learning rate\n",
    "    previous_learning_rate = current_learning_rate\n",
    "    scheduler.step(val_loss)\n",
    "    current_learning_rate = optimizer.param_groups[0]['lr']\n",
    "    if previous_learning_rate != current_learning_rate:\n",
    "        print(f\"Learning rate decayed to {current_learning_rate}\")\n",
    "    \n",
    "    ## save the model checkpoint\n",
    "    if avg_acc > best_val_acc:\n",
    "        best_val_acc = avg_acc\n",
    "        if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "           os.makedirs(CHECKPOINT_FOLDER)\n",
    "        print(\"Saving ...\")\n",
    "        state = {'state_dict': net.state_dict(),\n",
    "                'epoch': i,\n",
    "                'lr': current_learning_rate}\n",
    "        saveName = 'CNN_quantizeTrained' if ENABLE_QUANTIZATION else 'CNN'\n",
    "        torch.save(state, os.path.join(CHECKPOINT_FOLDER, saveName + '.pth'))\n",
    "    print('')\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in init_conv: 0.00%\n",
      "Sparsity in features.0.0.conv1: 99.77%\n",
      "Sparsity in features.0.0.conv2: 99.96%\n",
      "Sparsity in features.0.0.shortcut.0: 0.00%\n",
      "Sparsity in features.0.1.conv1: 99.96%\n",
      "Sparsity in features.0.1.conv2: 99.96%\n",
      "Sparsity in features.0.2.conv1: 99.96%\n",
      "Sparsity in features.0.2.conv2: 99.96%\n",
      "Sparsity in features.1.0.conv1: 99.98%\n",
      "Sparsity in features.1.0.conv2: 99.99%\n",
      "Sparsity in features.1.0.shortcut.0: 0.00%\n",
      "Sparsity in features.1.1.conv1: 99.99%\n",
      "Sparsity in features.1.1.conv2: 99.99%\n",
      "Sparsity in features.1.2.conv1: 99.99%\n",
      "Sparsity in features.1.2.conv2: 99.99%\n",
      "Sparsity in features.2.0.conv1: 99.99%\n",
      "Sparsity in features.2.0.conv2: 100.00%\n",
      "Sparsity in features.2.0.shortcut.0: 0.00%\n",
      "Sparsity in features.2.1.conv1: 100.00%\n",
      "Sparsity in features.2.1.conv2: 100.00%\n",
      "Sparsity in features.2.2.conv1: 100.00%\n",
      "Sparsity in features.2.2.conv2: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def check_sparsity(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            # Ensure the weight is on CPU for sparsity check\n",
    "            weight = module.weight.data\n",
    "            if weight.is_sparse:\n",
    "                weight = weight.to_dense()  # Convert to dense if sparse for computation\n",
    "            weight = weight.cpu()  # Move to CPU\n",
    "            sparsity = float(torch.sum(weight == 0)) / float(weight.nelement())\n",
    "            print(f\"Sparsity in {name}: {sparsity * 100:.2f}%\")\n",
    "\n",
    "check_sparsity(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Size: 2.10 MB\n"
     ]
    }
   ],
   "source": [
    "quantizedModel = True\n",
    "net.to('cpu')\n",
    "device = 'cpu'\n",
    "torch.quantization.convert(net.eval(), inplace=True)\n",
    "\n",
    "saveName = 'CNN' + '_quantized' if quantizedModel else 'CNN'\n",
    "torch.save(net.state_dict(), os.path.join(CHECKPOINT_FOLDER, saveName + '.pth'))\n",
    "\n",
    "# Check the size of the quantized model\n",
    "model_size_bytes = os.path.getsize(CHECKPOINT_FOLDER + '/' + saveName + '.pth')\n",
    "model_size_mb = model_size_bytes / (1024 * 1024)  # Convert bytes to megabytes\n",
    "print(f\"Quantized Model Size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8549, Accuracy: 33.34%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.34"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            loss += criterion(outputs, labels).item() * images.size(0)\n",
    "    \n",
    "    avg_loss = loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "evaluate_model(net, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
